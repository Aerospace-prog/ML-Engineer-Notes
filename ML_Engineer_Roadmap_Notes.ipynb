{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCoy6Xm+g/zE64Idwf/9R2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aerospace-prog/ML-Engineer-Notes/blob/main/ML_Engineer_Roadmap_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Engineer Notes and Code Logic"
      ],
      "metadata": {
        "id": "0jC0x31zXfMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Models\n"
      ],
      "metadata": {
        "id": "bF-r7Ptbd0VR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN (K-Nearest Neighbors)"
      ],
      "metadata": {
        "id": "GbAjuJ6YXi6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "\n",
        "#1 Data : [Height in cm , Weight in kg]\n",
        "X_train = [[150, 45], [155, 50], [175, 80], [180, 90]]\n",
        "y_train = [\"Small\", \"Small\", \"Large\", \"Large\"]\n",
        "\n",
        "#2 Model : Lazy Learning - it just stores the data\n",
        "model = KNeighborsClassifier(n_neighbors = 3)\n",
        "model.fit(X_train , y_train)\n",
        "\n",
        "#3 Predict :  New person: 160cm, 55kg.\n",
        "# The model measures distance to all 4 points above and picks the closest 3.\n",
        "\n",
        "X_new = np.array([[160,55]])\n",
        "preds = model.predict(X_new)\n",
        "print(preds)\n",
        "# Output: ['Small'] (Because it's closer to the 150/155 data points)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYvCr8QwXoYu",
        "outputId": "8ff9b9bb-8069-45b9-d8af-4464f0b3bead"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Small']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LogisticRegression (Classification Model)"
      ],
      "metadata": {
        "id": "dasceGSXY0yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Data: [Hours Studied, Hours Slept]\n",
        "X = [[2, 5], [3, 6], [8, 7], [10, 8]]\n",
        "# Label: 0 = Fail, 1 = Pass\n",
        "y = [0, 0, 1, 1]\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X,y)\n",
        "\n",
        "# Prediction\n",
        "test_student = [[6,7]]\n",
        "\n",
        "#1 Hard Predict :- Answer in Yes or No/True or False\n",
        "print(model.predict(test_student))\n",
        "\n",
        "#2 Soft Predict :- Answer in Probability\n",
        "print(model.predict_proba(test_student))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr1OnzHeY5ll",
        "outputId": "50212ce5-55ae-4276-bf38-de955ec53c18"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n",
            "[[0.39946336 0.60053664]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM (Support Vector Machines)"
      ],
      "metadata": {
        "id": "Pne5XVHCaoMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "# Data: [Height, Weight]\n",
        "# 0 = Basketball Player, 1 = Sumo Wrestler\n",
        "X = [[200, 100], [210, 110], [170, 150], [175, 160]]\n",
        "y = [0, 0, 1, 1]\n",
        "\n",
        "# 1 Linear Kernel : For simple straight line\n",
        "# model = svm.SVC(kernal = 'linear')\n",
        "\n",
        "# 2 RBF Kernel : Radial Basis Function - The \"Lifting\" Trick)\n",
        "# Used when data is curvy or complex\n",
        "model = svm.SVC(kernel = 'rbf')\n",
        "\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict\n",
        "print(model.predict([[180, 155]]))\n",
        "# Output: [1] (Likely a Sumo Wrestler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuTFUMmhar5V",
        "outputId": "eb8a3d17-e958-48d9-e700-e792293a3077"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree & Random Forest"
      ],
      "metadata": {
        "id": "ftuOB8vUeo5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Data: [Wings?, Barks?, Fur?]\n",
        "# 1=Yes, 0=No\n",
        "X = [[0, 1, 1], [1, 0, 0], [0, 0, 1], [0, 1, 1]]\n",
        "y = [\"Dog\", \"Bird\", \"Cat\", \"Dog\"]\n",
        "\n",
        "# --- OPTION 1: Single Decision Tree ---\n",
        "# Good for explaining \"Why\", but can over-memorize (Overfit)\n",
        "tree_model = DecisionTreeClassifier()\n",
        "tree_model.fit(X, y)\n",
        "\n",
        "# --- OPTION 2: Random Forest ---\n",
        "# Builds 100 trees (n_estimators=100). Harder to explain, but much more accurate.\n",
        "forest_model = RandomForestClassifier(n_estimators=100)\n",
        "forest_model.fit(X, y)\n",
        "\n",
        "# Predict: No wings, No bark, Has fur\n",
        "print(\"Forest Model\\n\")\n",
        "print(forest_model.predict([[0, 0, 1]]))\n",
        "print(\"Tree Model\\n\")\n",
        "print(tree_model.predict([[0, 0, 1]]))\n",
        "# Output: ['Cat']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfV4FfZIexxo",
        "outputId": "492f460a-a547-4a4b-ebb3-21f4ff2d888b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forest Model\n",
            "\n",
            "['Cat']\n",
            "Tree Model\n",
            "\n",
            "['Cat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting Machine\n"
      ],
      "metadata": {
        "id": "bXo3vkVAjTY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KIiqPWXjbeu",
        "outputId": "727884ac-72fa-431d-9687-f7304953dd28"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.29.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost is not in sklearn standard library, you usually install it separately\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Data: [Credit Score, Debt, Income]\n",
        "X = [[600, 5000, 30], [800, 0, 100], [550, 10000, 25], [750, 2000, 80]]\n",
        "# Label: 1 = Default (Bad), 0 = Pay (Good)\n",
        "y = [1, 0, 1, 0]\n",
        "\n",
        "# Split data (Crucial for boosting to prevent overfitting)\n",
        "X_train , X_test , y_train , y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size = 0.2\n",
        ")\n",
        "\n",
        "# 1. Initialize XGBoost\n",
        "# n_estimators=100 (100 shots/trees)\n",
        "# learning_rate=0.1 (Don't correct too fast, take small steps)\n",
        "model = XGBClassifier(n_estimators = 100 , learning_rate = 0.1)\n",
        "\n",
        "# 2. Train\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "# 3. Predict\n",
        "print(model.predict([[620, 4000, 35]]))\n",
        "# Output: [1] (Likely to default)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm_x4cwDlNfK",
        "outputId": "b538983a-05e2-4087-a7ef-1408a3c6edbc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression Models"
      ],
      "metadata": {
        "id": "Z4tFa_qRnTqa"
      }
    }
  ]
}